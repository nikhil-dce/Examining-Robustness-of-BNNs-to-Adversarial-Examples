{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import math\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from deepfool import deepfool\n",
    "import os,sys\n",
    "from FGSM import fgsm,fgsm_graybox\n",
    "from train_mnist_model import Net\n",
    "from tqdm import tqdm\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "# homedir = '/home/nikhil/Examining-Robustness-of-BNNs-to-Adversarial-Examples/'\n",
    "homedir = '/home/serge/Documents/Classes/Adversarial_ML/Examining-Robustness-of-BNNs-to-Adversarial-Examples/'\n",
    "MODULE_PATH = ['{}BNN_Implementations/PyTorch-BayesianCNN-master'.format(homedir),\n",
    "          '{}BNN_Implementations/PyTorch-BayesianCNN-master/models/BayesianModels'.format(homedir)]\n",
    "\n",
    "for m in MODULE_PATH:\n",
    "    sys.path.append(m)\n",
    "\n",
    "import data\n",
    "from BayesianLeNet import BBBLeNet\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# test_loader = test_loader = torch.utils.data.DataLoader(\n",
    "#         dsets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                            transforms.ToTensor(),\n",
    "#                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "#                        ])),\n",
    "#         batch_size=1000, shuffle=False)\n",
    "\n",
    "dataset = 'MNIST'\n",
    "batch_size=1000\n",
    "valid_size = 0.2 # will not be used \n",
    "num_workers = 0\n",
    "\n",
    "trainset, testset, inputs, outputs = data.getDataset(dataset)\n",
    "train_loader, valid_loader, test_loader = data.getDataloader(trainset, testset, valid_size, \n",
    "                                                             batch_size, num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_fgsm(model,loss,eps,device,loader,is_bayes=False):\n",
    "    original_preds_soft = []\n",
    "    attack_preds_soft = []\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        attack_images = fgsm(model=model,loss=loss,device=device,images=images,labels=labels,eps=eps,is_bayes=is_bayes)\n",
    "        \n",
    "        if is_bayes:\n",
    "            original_preds_soft.append(model(images.to(device))[0].detach())\n",
    "            attack_preds_soft.append(model(attack_images)[0].detach())\n",
    "        else:\n",
    "            original_preds_soft.append(model(images.to(device)).detach())\n",
    "            attack_preds_soft.append(model(attack_images).detach())\n",
    "        \n",
    "    original_preds_soft = torch.cat(original_preds_soft, dim=0)\n",
    "    attack_preds_soft = torch.cat(attack_preds_soft,dim=0)\n",
    "    original_preds = torch.argmax(original_preds_soft,axis=1)\n",
    "    attack_preds = torch.argmax(attack_preds_soft,axis=1)\n",
    "    \n",
    "    success_rate = torch.mean((original_preds!=attack_preds).type(torch.DoubleTensor)).cpu().detach().numpy()\n",
    "    entropy = np.mean(Categorical(probs = attack_preds_soft).entropy().cpu().detach().numpy())\n",
    "    return success_rate,entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example attack on a non-Bayes CNN (MNIST)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('mnist_cnn.pt'))\n",
    "model.eval()\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.linspace(0,2,101)\n",
    "success_rates = []\n",
    "entropies = []\n",
    "for eps in tqdm(epsilons):\n",
    "    success_rate,entropy = attack_fgsm(model,loss,eps,device,test_loader)\n",
    "    success_rates.append(success_rate)\n",
    "    entropies.append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epsilons,success_rates)\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('Attack success rate')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epsilons,entropies)\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('Average predictive entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example attack on BayesNet"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BBBLeNet(outputs=10,inputs=1)\n",
    "ckpt_path = 'BNN_Implementations/PyTorch-BayesianCNN-master/checkpoints/MNIST/bayesian'\n",
    "ckpt_name = 'model_lenet.pt'\n",
    "model.load_state_dict(torch.load(os.path.join(homedir,ckpt_path,ckpt_name)))\n",
    "model.eval()\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "loss = metrics.ELBO(len(test_loader.dataset)).to(device)\n",
    "# loss = F.nll_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.linspace(0,0.5,20)\n",
    "success_rates = []\n",
    "entropies = []\n",
    "for eps in tqdm(epsilons):\n",
    "    success_rate,entropy = attack_fgsm(model,loss,eps,device,test_loader,is_bayes=True)\n",
    "    success_rates.append(success_rate)\n",
    "    entropies.append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epsilons,success_rates)\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('Attack success rate')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epsilons,entropies)\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('Average predictive entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}