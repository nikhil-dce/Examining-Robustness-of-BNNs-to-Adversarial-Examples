# Examining-Robustness-of-BNNs-to-Adversarial-Examples

This is course project for ECE 590: ML for Security.

---------------------------------------------------------------------------------------------------------

### MNIST RESULTS
![Accuracy and Predictive Entropy](Adversarial_Methods/Deep_Fool_Code/MNIST_adv_attack.png)

---------------------------------------------------------------------------------------------------------

### Fashion MNIST RESULTS
![Accuracy and Predictive Entropy](Adversarial_Methods/Deep_Fool_Code/FashionMNIST_adv_attack.png)

---------------------------------------------------------------------------------------------------------

### CIFAR10 RESULTS
![Accuracy and Predictive Entropy](Adversarial_Methods/Deep_Fool_Code/CIFAR10_adv_attack.png)

---------------------------------------------------------------------------------------------------------

## FGSM on Bayesian and Frequentist models

![Attack on Bayesian LeNet trained on MNIST](Adversarial_Methods/Deep_Fool_Code/bayes_MNIST_attacks.png)

![Attack on Frequentist LeNet trained on MNIST](Adversarial_Methods/Deep_Fool_Code/freq_MNIST_attacks.png)

![Attack on Bayesian LeNet trained on Fashion MNIST](Adversarial_Methods/Deep_Fool_Code/bayes_FashionNIST_attacks.png)

![Attack on Frequentist LeNet trained on Fashion MNIST](Adversarial_Methods/Deep_Fool_Code/freq_FashionMNIST_attacks.png)

![Attack on Bayesian LeNet trained on CIFAR10](Adversarial_Methods/Deep_Fool_Code/bayes_CIFAR10_attacks.png)

![Attack on Frequentist LeNet trained on CIFAR10](Adversarial_Methods/Deep_Fool_Code/freq_CIFAR10_attacks.png)